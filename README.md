**This project's code was developed under the guidance of Prof.Dr. MURAT EKİNCİ in the Neural Network course at Karadeniz Technical University in Computer Science Field.
You can find the reports pdf written about the project in the repository.**


This Two project presents an interactive graphical tool for exploring and understanding Single Layer and Multi - Class Single Layer perceptron learning and visualization of the decision boundary. Users can intuitively interact with the application by adding data points and training a perceptron model to classify points into multiple classes using the sigmoid activation function.

-------------------------------------------------**Single-Layer**-----------------------------------

**Input Window before Training Model**


![image](https://github.com/user-attachments/assets/4df8d2ce-178d-4782-b65b-8ecc0c744308)

 In this window, you can select classes from a dropdown menu and place dots on the coordinates to provide samples for the selected classes. After that, when you press 'Train Model,' it will separate the classes using a linear boundary.

**Output Window after Training Model**


![image](https://github.com/user-attachments/assets/0ddf710a-9d1c-46ea-9f45-65ae53d627da)



-------------------------------------------------------**Multi-Class-Single**---------------------------------------------------

This project includes two dropdown menus. The first dropdown allows you to select the number of classes for which you want to provide samples, and the second dropdown lets you choose a specific class to assign dots or samples. Once you have assigned dots or samples to the classes, you can proceed to train the model.

**Input Window before Training Model**

![image](https://github.com/user-attachments/assets/e5c2b419-b429-436a-9907-c7b902e6f85c)



**Output Window after Training Model**

![image](https://github.com/user-attachments/assets/3954c3f8-00f8-4b6d-a9be-4ffdb9b61fa7)


--------------------------------------------------**Multi-Layer**--------------------------------------------------------------

This code is similar to a multi-class single-layer network, but with a few key differences. It includes a hidden input layer with multiple neurons, and it uses the ReLU activation function for added flexibility and performance.



**Input Window before Training Model**

![image](https://github.com/user-attachments/assets/f6990a66-3f6a-48a4-8d45-c97a5b4d841c)
![image](https://github.com/user-attachments/assets/44f61ada-40e1-440d-8e64-ff6bbdd5f719)



**Output Window after Training Model**

![image](https://github.com/user-attachments/assets/50621693-dd03-4467-8272-4ba0b07b2481)

